# Natural Language Processing Projects 

![Python](https://img.shields.io/badge/Python%2B-blue?style=for-the-badge&logo=python)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch)
![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD21E?style=for-the-badge&logo=huggingface)

Repository containing the projects developed for the **Natural Language Processing** course within the Master's Degree in Artificial Intelligence at the **University of Bologna**.

**Authors:**
* **Samuele Centanni** 
* **Tomaz Cotic**
* **Mattia Lodi**

---

## Project Overview

This repository explores different approaches to text classification, moving from traditional supervised learning with RNNs and Transformers to advanced prompting techniques with Large Language Models (LLMs).

| Assignment | Topic | Key Models |
| :--- | :--- | :--- |
| **#1** | **Hate Speech Detection** | BiLSTM, RoBERTa, DeBERTa, SVM |
| **#2** | **Few-Shot LLM Inference** | Mistral-7B-v0.3, Llama-3.1-8B |

---

## Assignment 1: Text Classification with Deep Learning

### ðŸŽ¯ Objective
Classify tweets into four distinct categories related to sexism and hate speech: `not-sexist`, `direct`, `judgmental`, and `reported`. The goal was to compare the performance of increasing model complexity, from simple baselines to state-of-the-art Transformers.

### Models & Architecture
We implemented and compared the following architectures:
* **Baseline:** SVM (Support Vector Machine).
* **RNNs:**
    * **BiLSTM:** 1-layer and 2-layer configurations with custom embeddings.
    * **Bi-GRU:** Tested as an alternative gating mechanism.
* **Transformers:**
    * **RoBERTa:** Specifically the `RoBERTa-hate-speech` fine-tuned version.
    * **DeBERTa-v3-base:** Tested for comparison against RoBERTa.

### ðŸ“Š Key Results
We evaluated models using the **F1-score**. The Transformer-based models significantly outperformed the RNNs and the SVM baseline. Interestingly, the domain-specific *RoBERTa-hate-speech* outperformed the architecturally superior *DeBERTa-v3*, proving the value of domain adaptation.

| Model | F1-Score (Best) |
| :--- | :--- |
| **RoBERTa** | **0.5305** |
| DeBERTa | 0.5021 |
| 2-layer BiLSTM | 0.3637 |
| 1-layer BiLSTM | 0.3573 |

> **Note:** The `Reported` and `Judgmental` classes proved difficult for all models due to high semantic ambiguity and dataset imbalance.

---

## Assignment 2: Zero-shot & Few-shot Inference with LLMs

### ðŸŽ¯ Objective
Perform a 5-class text classification task (`not-sexist`, `animosity`, `prejudiced`, `threats`, `derogation`) using Large Language Models without fine-tuning. [cite_start]We investigated how different prompting strategies affect performance.

### ðŸ§  Models Used
* **Mistral-7B-v0.3**
* **Llama-3.1-8B**

### Experimental Setup
We tested three distinct inference modes:
1.  **Zero-shot:** Direct classification without examples.
2.  **Few-shot (Random):** $N$ examples sampled randomly from the dataset ($N \in \{2, 4, 6\}$).
3.  **Few-shot (Similarity-based):** $N$ examples selected dynamically using **Cosine Similarity** on embeddings generated by `BGE-large-en-v1.5`.

### ðŸ“ˆ Key Findings
* **Similarity Matters:** Selecting demonstrations based on semantic similarity significantly boosts performance for both models compared to random selection.
* **Model Behavior:** Mistral benefits more from random demonstrations, whereas Llama's performance can degrade if examples are not chosen carefully.
* **Best Configuration:** Mistral generally outperformed Llama in the similarity-based setting.

**Performance Snapshot (F1-score):**

| Mode | Mistral-7B | Llama-3.1 |
| :--- | :--- | :--- |
| **Zero-shot** | 0.3738 | **0.6200** |
| **Few-shot (Similarity, k=4)** | **0.5476** | 0.5304 |
